{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a49b3787",
   "metadata": {},
   "source": [
    "# *Nano Graph Rag: Fake News Detection*\n",
    "### *Aman Pawar*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d009f598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 00:45:44,418 - INFO - [MainProcess] Multiprocessing start method set to 'spawn' (was None).\n",
      "2025-04-11 00:45:44,421 - INFO - [MainProcess] CUDA available. Using device: cuda\n",
      "2025-04-11 00:45:44,421 - INFO - [MainProcess] Mixed Precision Training (AMP) enabled: True\n",
      "2025-04-11 00:45:44,422 - INFO - [MainProcess] --- Setting up Retriever ---\n",
      "2025-04-11 00:45:44,883 - INFO - [MainProcess] Loaded 6420 samples from ../Constraint_English_Train.xlsx (dropped 0 for NaN tweet, 0 for invalid label).\n",
      "2025-04-11 00:45:44,884 - INFO - [MainProcess] Loading retriever model: all-MiniLM-L6-v2...\n",
      "2025-04-11 00:45:44,885 - INFO - [MainProcess] Use pytorch device_name: cuda:0\n",
      "2025-04-11 00:45:45,067 - INFO - [MainProcess] Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2025-04-11 00:45:49,542 - INFO - [MainProcess] Retriever model 'all-MiniLM-L6-v2' loaded and moved to cuda.\n",
      "2025-04-11 00:45:49,544 - INFO - [MainProcess] Embedding 6420 training documents for FAISS index...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38936b42c8a943a6955c64a60a623bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 00:45:51,717 - INFO - [MainProcess] Embeddings generated with shape: torch.Size([6420, 384])\n",
      "2025-04-11 00:45:51,924 - INFO - [MainProcess] Building FAISS index (IVFFlat) with dimension=384...\n",
      "2025-04-11 00:45:51,925 - INFO - [MainProcess] Training FAISS IVFFlat index with nlist=100...\n",
      "2025-04-11 00:45:52,200 - INFO - [MainProcess] FAISS index training finished in 0.27s.\n",
      "2025-04-11 00:45:52,258 - INFO - [MainProcess] Set FAISS nprobe to 10\n",
      "2025-04-11 00:45:52,268 - INFO - [MainProcess] FAISS index built successfully. Type: IVFFlat, Total vectors: 6420\n",
      "2025-04-11 00:45:52,269 - INFO - [MainProcess] --- Loading Data and Creating DataLoaders ---\n",
      "2025-04-11 00:45:52,406 - INFO - [MainProcess] Loaded 2140 samples from ../Constraint_English_Val.xlsx (dropped 0 for NaN tweet, 0 for invalid label).\n",
      "2025-04-11 00:45:52,542 - INFO - [MainProcess] Loaded 2140 samples from ../english_test_with_labels.xlsx (dropped 0 for NaN tweet, 0 for invalid label).\n",
      "2025-04-11 00:45:52,542 - INFO - [MainProcess] Loading classifier tokenizer: distilbert-base-uncased...\n",
      "2025-04-11 00:45:52,819 - INFO - [MainProcess] Classifier tokenizer loaded.\n",
      "2025-04-11 00:45:52,820 - INFO - [MainProcess] Creating datasets...\n",
      "2025-04-11 00:45:52,821 - INFO - [MainProcess] Dataset initialized with 6420 samples.\n",
      "2025-04-11 00:45:52,821 - INFO - [MainProcess] Dataset initialized with 2140 samples.\n",
      "2025-04-11 00:45:52,822 - INFO - [MainProcess] Dataset initialized with 2140 samples.\n",
      "2025-04-11 00:45:52,823 - INFO - [MainProcess] Datasets created.\n",
      "2025-04-11 00:45:52,823 - INFO - [MainProcess] Using 4 dataloader workers (CUDA + spawn method detected).\n",
      "2025-04-11 00:45:52,824 - INFO - [MainProcess] DataLoader pin_memory set to: True\n",
      "2025-04-11 00:45:52,824 - INFO - [MainProcess] DataLoaders created.\n",
      "2025-04-11 00:45:52,825 - INFO - [MainProcess]   Train DataLoader: 401 batches.\n",
      "2025-04-11 00:45:52,825 - INFO - [MainProcess]   Validation DataLoader: 134 batches.\n",
      "2025-04-11 00:45:52,826 - INFO - [MainProcess]   Test DataLoader: 134 batches.\n",
      "2025-04-11 00:45:52,826 - INFO - [MainProcess] --- Initializing Classifier Model ---\n",
      "2025-04-11 00:45:52,827 - INFO - [MainProcess] Loading classifier model: distilbert-base-uncased...\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-04-11 00:45:53,184 - INFO - [MainProcess] Classifier model loaded and moved to device.\n",
      "2025-04-11 00:45:53,185 - INFO - [MainProcess] --- Setting up Training Components ---\n",
      "2025-04-11 00:45:53,187 - INFO - [MainProcess] Optimizer, Scheduler, Loss Function, and GradScaler (AMP enabled: True) initialized.\n",
      "2025-04-11 00:45:53,188 - INFO - [MainProcess] Total training steps (considering grad accum): 1203\n",
      "2025-04-11 00:45:53,188 - INFO - [MainProcess] Warmup steps: 100\n",
      "2025-04-11 00:45:53,189 - INFO - [MainProcess] --- Starting Training ---\n",
      "2025-04-11 00:45:53,189 - INFO - [MainProcess] Tip: For further speed optimization, consider profiling the code using tools like cProfile or torch.profiler.\n",
      "2025-04-11 00:45:53,190 - INFO - [MainProcess] ===== Epoch 1/3 =====\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/ankit/miniconda3/envs/ap/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/ankit/miniconda3/envs/ap/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'GraphRagNewsDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 706\u001b[0m\n\u001b[1;32m    703\u001b[0m processed_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    704\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 706\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m Training\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(progress_bar):\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m batch \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m batch \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m batch:\n",
      "File \u001b[0;32m~/miniconda3/envs/ap/lib/python3.9/site-packages/tqdm/notebook.py:223\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m colour \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolour\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    222\u001b[0m display_here \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgui\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39m_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m__: \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ap/lib/python3.9/site-packages/tqdm/asyncio.py:33\u001b[0m, in \u001b[0;36mtqdm_asyncio.__init__\u001b[0;34m(self, iterable, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterable_next \u001b[38;5;241m=\u001b[39m iterable\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__next__\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterable_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterable_next \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterable_iterator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__next__\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ap/lib/python3.9/site-packages/torch/utils/data/dataloader.py:491\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ap/lib/python3.9/site-packages/torch/utils/data/dataloader.py:422\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ap/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1139\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1146\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/miniconda3/envs/ap/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ap/lib/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ap/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ap/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ap/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ap/lib/python3.9/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Fast Graph-RAG Implementation (Adapted for Nano/Speed).\n",
    "\n",
    "This script implements a Retrieval-Augmented Generation (RAG) approach\n",
    "for text classification, adapted for faster execution (\"Fast-Graph-RAG\" or \"Nano-Graph-RAG\").\n",
    "Key adaptations include:\n",
    "- Using DistilBERT as the classifier for faster training/inference.\n",
    "- Employing FAISS IndexIVFFlat for faster approximate nearest neighbor search.\n",
    "- Adding optional mixed-precision training (torch.cuda.amp).\n",
    "- Configuration options tailored for speed vs. accuracy trade-offs.\n",
    "\n",
    "Core Components:\n",
    "1. Configuration: Hyperparameters, paths, model names, FAISS settings, AMP flag.\n",
    "2. Data Loading: Loads and preprocesses data.\n",
    "3. Custom Dataset (GraphRagNewsDataset): Integrates retrieval.\n",
    "4. Retriever Setup: SentenceTransformer + FAISS (IndexIVFFlat).\n",
    "5. Graph-like Retrieval Function: Finds primary/secondary neighbors using FAISS.\n",
    "6. Classifier Model: DistilBERT for sequence classification.\n",
    "7. Training Loop: Fine-tunes the classifier with optional AMP.\n",
    "8. Evaluation: Measures performance.\n",
    "\n",
    "*** IMPORTANT EXECUTION NOTE ***\n",
    "This script uses multiprocessing for data loading. Due to how Python's\n",
    "multiprocessing (especially with 'spawn' start method) works, it's crucial\n",
    "to run this script as a standalone .py file from your terminal:\n",
    "  python <your_script_name>.py\n",
    "Running cells interactively (e.g., in some IDEs or notebooks) might lead to\n",
    "AttributeErrors or NameErrors related to multiprocessing context.\n",
    "******************************\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.multiprocessing as mp # Import torch multiprocessing\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss # For efficient similarity search\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import time\n",
    "import gc # Garbage collector\n",
    "import traceback # For detailed error printing\n",
    "import logging # Using logging for better output management\n",
    "from torch.cuda.amp import GradScaler, autocast # For Mixed Precision Training\n",
    "\n",
    "# --- Set Environment Variable to Suppress Tokenizer Parallelism Warning ---\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# --- Configure Logging ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - [%(processName)s] %(message)s') # Added process name\n",
    "\n",
    "# --- Declare Global Variables for Multiprocessing ---\n",
    "# These will be assigned in the __main__ block but need to be accessible\n",
    "# by the retrieve_documents_graph_like function running in worker processes.\n",
    "retriever_model = None\n",
    "faiss_index = None\n",
    "train_embeddings_cpu = None\n",
    "train_texts = []\n",
    "\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "class Config:\n",
    "    \"\"\"Configuration class for hyperparameters and settings.\"\"\"\n",
    "    # File paths (Update these paths if your files are located elsewhere)\n",
    "    # IMPORTANT: Ensure these paths are correct relative to where you run the script.\n",
    "    # Using relative paths assuming data is one level up\n",
    "    train_file = '../Constraint_English_Train.xlsx'\n",
    "    val_file = '../Constraint_English_Val.xlsx'\n",
    "    test_file = '../english_test_with_labels.xlsx'\n",
    "\n",
    "    # Model names\n",
    "    retriever_model_name = 'all-MiniLM-L6-v2' # Still a good balance of speed/accuracy\n",
    "    # Using DistilBERT for faster classification\n",
    "    classifier_model_name = 'distilbert-base-uncased'\n",
    "\n",
    "    # RAG parameters (Adjust k/m for speed vs. context trade-off)\n",
    "    num_retrieved_docs_primary = 3 # 'k': How many direct neighbors\n",
    "    num_retrieved_docs_secondary = 2 # 'm': How many neighbors of neighbors\n",
    "    max_total_retrieved_docs = 5 # Total unique docs (primary + secondary)\n",
    "\n",
    "    # FAISS Index Parameters (Using IVFFlat for speed)\n",
    "    faiss_index_type = 'IVFFlat' # Options: 'IVFFlat', 'FlatL2'\n",
    "    # Number of centroids for IVFFlat. Rule of thumb: ~4*sqrt(N) to 16*sqrt(N)\n",
    "    # Adjust based on your training data size (N = len(train_texts))\n",
    "    # Example: If N=6400, sqrt(N)=80. nlist could be 320 to 1280.\n",
    "    # Start with a moderate value. Increase for potentially better accuracy but slower build/search.\n",
    "    faiss_nlist = 100 # Number of Voronoi cells (centroids)\n",
    "    # Number of cells to probe during search. Higher means more accuracy but slower search.\n",
    "    faiss_nprobe = 10\n",
    "\n",
    "    # Training parameters\n",
    "    max_seq_length = 512 # Max length for DistilBERT input\n",
    "    batch_size = 16 # Can often increase batch size with DistilBERT/AMP\n",
    "    epochs = 3\n",
    "    learning_rate = 3e-5 # Adjusted slightly for DistilBERT, may need tuning\n",
    "    warmup_steps = 100\n",
    "    gradient_accumulation_steps = 1\n",
    "\n",
    "    # Hardware, Reproducibility, and Speed-ups\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    seed = 42\n",
    "    # Enable Mixed Precision Training (requires CUDA and compatible hardware)\n",
    "    # Set to False if encountering issues or not using a suitable GPU.\n",
    "    use_amp = torch.cuda.is_available() # Enable AMP if CUDA is available\n",
    "\n",
    "    # Output directory\n",
    "    output_dir = \"./fast_graph_rag_classifier_model\"\n",
    "\n",
    "    # --- DEBUGGING FLAG ---\n",
    "    # Set to True to force num_workers=0 in DataLoaders for easier debugging\n",
    "    # Set back to False once multiprocessing issues are resolved\n",
    "    DEBUG_DATALOADER = False\n",
    "\n",
    "# --- 2. Data Loading Function ---\n",
    "# Defined at top level (module scope)\n",
    "def load_data(filepath):\n",
    "    \"\"\"Loads data from Excel, cleans, maps labels.\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        logging.error(f\"Data file not found: {filepath}\")\n",
    "        return None\n",
    "    try:\n",
    "        df = pd.read_excel(filepath)\n",
    "        if 'tweet' not in df.columns or 'label' not in df.columns:\n",
    "            logging.error(f\"Excel file {filepath} must contain 'tweet' and 'label' columns.\")\n",
    "            return None\n",
    "\n",
    "        initial_count = len(df)\n",
    "        df = df.dropna(subset=['tweet'])\n",
    "        df['tweet'] = df['tweet'].astype(str)\n",
    "        dropped_nan_tweet = initial_count - len(df)\n",
    "\n",
    "        df['label'] = df['label'].map({'real': 1, 'fake': 0})\n",
    "        initial_count_before_label_drop = len(df)\n",
    "        df = df.dropna(subset=['label']) # Drop rows where label mapping failed (NaN)\n",
    "        df['label'] = df['label'].astype(int)\n",
    "        dropped_bad_label = initial_count_before_label_drop - len(df)\n",
    "\n",
    "        if df.empty:\n",
    "            logging.warning(f\"No valid data loaded from {filepath} after cleaning.\")\n",
    "            return None\n",
    "\n",
    "        logging.info(f\"Loaded {len(df)} samples from {filepath} (dropped {dropped_nan_tweet} for NaN tweet, {dropped_bad_label} for invalid label).\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading {filepath}: {e}\", exc_info=True)\n",
    "        return None\n",
    "\n",
    "# --- 3. Custom PyTorch Dataset for Graph-RAG ---\n",
    "# Defined at top level (module scope) - Crucial for multiprocessing\n",
    "class GraphRagNewsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for Graph-RAG. Retrieves context using a retriever function\n",
    "    and tokenizes the combined text. Includes detailed error handling.\n",
    "    \"\"\"\n",
    "    def __init__(self, texts, labels, tokenizer, max_len, retriever_func, num_retrieved_total):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.retriever_func = retriever_func\n",
    "        self.num_retrieved_total = num_retrieved_total\n",
    "\n",
    "        # Ensure inputs are lists\n",
    "        if not isinstance(self.texts, list): self.texts = list(self.texts)\n",
    "        if not isinstance(self.labels, list): self.labels = list(self.labels)\n",
    "        if len(self.texts) != len(self.labels):\n",
    "            raise ValueError(f\"Number of texts ({len(self.texts)}) and labels ({len(self.labels)}) must match.\")\n",
    "        logging.info(f\"Dataset initialized with {len(self.texts)} samples.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves item, finds context, tokenizes, returns dict.\n",
    "        Includes detailed logging for debugging worker errors.\n",
    "        \"\"\"\n",
    "        original_text = None\n",
    "        label = None\n",
    "        try:\n",
    "            # Check index bounds rigorously\n",
    "            if not isinstance(idx, int) or not (0 <= idx < len(self.texts)):\n",
    "                logging.error(f\"Invalid index type or value: {idx} (type: {type(idx)}). Dataset size: {len(self.texts)}.\")\n",
    "                # Raise error if not in a daemon process (like main process or num_workers=0)\n",
    "                # Check if current process is a daemon (worker process often is)\n",
    "                current_process = mp.current_process()\n",
    "                if not hasattr(current_process, 'daemon') or not current_process.daemon:\n",
    "                    raise IndexError(f\"Invalid index: {idx}\")\n",
    "                return None # Return None if in a worker process to avoid crashing the loader\n",
    "\n",
    "            original_text = str(self.texts[idx]) # Ensure text is string\n",
    "            label = int(self.labels[idx]) # Ensure label is int\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to get text/label at index {idx}. Error: {e}\", exc_info=True)\n",
    "            current_process = mp.current_process()\n",
    "            if not hasattr(current_process, 'daemon') or not current_process.daemon: raise e\n",
    "            return None\n",
    "\n",
    "        # --- Retrieval Step ---\n",
    "        retrieved_docs = []\n",
    "        try:\n",
    "            # Call the retriever function (which now expects the model to be on the correct device)\n",
    "            # It will access the MODULE-LEVEL global variables.\n",
    "            retrieved_docs = self.retriever_func(original_text)\n",
    "            if not isinstance(retrieved_docs, list):\n",
    "                logging.warning(f\"Retriever function did not return a list for index {idx}. Query: '{original_text[:50]}...'. Got: {type(retrieved_docs)}. Using empty list.\")\n",
    "                retrieved_docs = []\n",
    "        except NameError as ne:\n",
    "             # Specific check for NameError which indicates globals might not be set in worker\n",
    "             logging.error(f\"NameError during RETRIEVAL for index {idx}. This likely means worker process couldn't access global retriever components. Error: {ne}\", exc_info=True)\n",
    "             retrieved_docs = []\n",
    "             # Raise if in main process, otherwise return None\n",
    "             current_process = mp.current_process()\n",
    "             if not hasattr(current_process, 'daemon') or not current_process.daemon: raise ne\n",
    "             return None\n",
    "        except Exception as e:\n",
    "            # Log detailed error including traceback if possible\n",
    "            logging.error(f\"Failed during RETRIEVAL for index {idx}. Query: '{original_text[:100]}...'. Error: {e}\", exc_info=True)\n",
    "            retrieved_docs = []\n",
    "            # Only raise if not in worker to allow dataloader to continue\n",
    "            current_process = mp.current_process()\n",
    "            if not hasattr(current_process, 'daemon') or not current_process.daemon: raise e\n",
    "            # If in worker, returning None might be better than empty list if it causes downstream issues\n",
    "            # return None # Consider returning None if retrieval failure should skip the item\n",
    "\n",
    "        # --- Tokenization Step ---\n",
    "        combined_text = original_text\n",
    "        try:\n",
    "            context = \" \".join([str(doc) for doc in retrieved_docs if doc]) # Filter out None or empty docs\n",
    "            sep_token = self.tokenizer.sep_token if self.tokenizer.sep_token else \"[SEP]\"\n",
    "\n",
    "            if context:\n",
    "                combined_text = f\"{original_text} {sep_token} {context}\"\n",
    "\n",
    "            # Tokenize the combined text\n",
    "            encoding = self.tokenizer.encode_plus(\n",
    "                combined_text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_len,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt', # Return PyTorch tensors\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed during TOKENIZATION for index {idx}. Combined Text (start): '{combined_text[:100]}...'. Error: {e}\", exc_info=True)\n",
    "            current_process = mp.current_process()\n",
    "            if not hasattr(current_process, 'daemon') or not current_process.daemon: raise e\n",
    "            return None\n",
    "\n",
    "        # --- Return Result ---\n",
    "        try:\n",
    "            # Ensure tensors are correctly shaped (flatten removes the batch dimension added by return_tensors='pt')\n",
    "            return {\n",
    "                'input_ids': encoding['input_ids'].flatten(),\n",
    "                'attention_mask': encoding['attention_mask'].flatten(),\n",
    "                'labels': torch.tensor(label, dtype=torch.long) # Ensure label is a tensor\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed during final DICT CREATION for index {idx}. Label: {label}. Error: {e}\", exc_info=True)\n",
    "            current_process = mp.current_process()\n",
    "            if not hasattr(current_process, 'daemon') or not current_process.daemon: raise e\n",
    "            return None\n",
    "\n",
    "\n",
    "# --- 4. Evaluation Function ---\n",
    "# Defined at top level (module scope)\n",
    "def evaluate_model(model, dataloader, device, loss_fn):\n",
    "    \"\"\"Evaluates the model on a given dataloader.\"\"\"\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    if dataloader is None or len(dataloader) == 0:\n",
    "        logging.warning(\"Evaluation dataloader is empty or None. Skipping evaluation.\")\n",
    "        return 0, 0, 0, 0, 0 # Return zero metrics\n",
    "\n",
    "    with torch.no_grad(): # Disable gradient calculations\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "            # Rigorous batch check\n",
    "            if not isinstance(batch, dict) or 'input_ids' not in batch or 'attention_mask' not in batch or 'labels' not in batch:\n",
    "                logging.warning(\"Skipping invalid batch during evaluation (not a dict or missing keys).\")\n",
    "                continue\n",
    "            if batch['input_ids'].numel() == 0 or batch['labels'].numel() == 0:\n",
    "                logging.warning(\"Skipping empty batch (zero elements in input_ids or labels) during evaluation.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                # No autocast needed for evaluation usually, unless facing memory issues\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "\n",
    "                # Calculate loss only if loss_fn is provided and valid\n",
    "                if callable(loss_fn):\n",
    "                    try:\n",
    "                        loss = loss_fn(logits, labels)\n",
    "                        total_loss += loss.item()\n",
    "                    except Exception as loss_e:\n",
    "                         logging.warning(f\"Could not compute loss for evaluation batch: {loss_e}\")\n",
    "\n",
    "\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error during evaluation batch processing: {e}\", exc_info=True)\n",
    "                # Optionally try to log batch details (shape, etc.) if error persists\n",
    "                # logging.error(f\"Batch keys: {batch.keys()}\")\n",
    "                # logging.error(f\"Input IDs shape: {batch.get('input_ids', 'N/A').shape}\")\n",
    "                continue # Skip the problematic batch\n",
    "\n",
    "    if not all_labels or not all_preds:\n",
    "        logging.warning(\"Evaluation resulted in no valid labels or predictions. Cannot compute metrics.\")\n",
    "        return 0, 0, 0, 0, 0\n",
    "\n",
    "    # Use len(all_labels) for averaging loss if loss calculation was skipped for some batches\n",
    "    num_valid_batches_for_loss = len(dataloader) # Approximation, could be refined if needed\n",
    "    avg_loss = total_loss / num_valid_batches_for_loss if callable(loss_fn) and num_valid_batches_for_loss > 0 else 0\n",
    "\n",
    "    try:\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        # Use 'binary' average for binary classification, report micro/macro/weighted for multiclass\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_labels, all_preds, average='binary', zero_division=0\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error calculating evaluation metrics: {e}\", exc_info=True)\n",
    "        accuracy, precision, recall, f1 = 0, 0, 0, 0\n",
    "\n",
    "    logging.info(f\"Evaluation Results: Loss={avg_loss:.4f}, Acc={accuracy:.4f}, Prec={precision:.4f}, Rec={recall:.4f}, F1={f1:.4f}\")\n",
    "    return avg_loss, accuracy, precision, recall, f1\n",
    "\n",
    "# --- 5. Graph-like Retrieval Function Definition ---\n",
    "# Defined at top level (module scope) - Crucial for multiprocessing\n",
    "def retrieve_documents_graph_like(query_text):\n",
    "    \"\"\"\n",
    "    Retrieves documents using similarity-based graph neighborhood approach.\n",
    "    Uses MODULE-LEVEL global variables: retriever_model, faiss_index,\n",
    "    train_embeddings_cpu, train_texts. Assumes these have been initialized\n",
    "    in the main process before workers are started.\n",
    "    \"\"\"\n",
    "    # Access module-level globals directly. Check if they are initialized.\n",
    "    if retriever_model is None or faiss_index is None or train_embeddings_cpu is None or not train_texts:\n",
    "        # This check might occur if a worker starts before initialization is fully complete,\n",
    "        # or if the globals weren't properly shared/initialized in the worker's context.\n",
    "        logging.warning(\"Retriever components (module globals) not initialized in this process. Cannot retrieve.\")\n",
    "        return []\n",
    "\n",
    "    k_primary = Config.num_retrieved_docs_primary\n",
    "    m_secondary = Config.num_retrieved_docs_secondary\n",
    "    max_total = Config.max_total_retrieved_docs\n",
    "\n",
    "    try:\n",
    "        # 1. Embed query\n",
    "        # Model should already be on Config.device\n",
    "        query_embedding = retriever_model.encode([query_text], convert_to_tensor=True, device=Config.device)\n",
    "        query_embedding_np = query_embedding.cpu().numpy().astype(np.float32)\n",
    "        del query_embedding\n",
    "\n",
    "        # 2. Find primary neighbors\n",
    "        search_k_primary = k_primary + m_secondary\n",
    "        distances_p, indices_p = faiss_index.search(query_embedding_np, search_k_primary)\n",
    "        primary_indices_all = set(idx for idx in indices_p[0] if idx != -1)\n",
    "        primary_indices = set(list(primary_indices_all)[:k_primary])\n",
    "\n",
    "        if not primary_indices:\n",
    "            return []\n",
    "\n",
    "        # 3. Find secondary neighbors\n",
    "        secondary_indices = set()\n",
    "        if m_secondary > 0 and primary_indices:\n",
    "            primary_indices_list = list(primary_indices)\n",
    "            try:\n",
    "                valid_primary_indices = [idx for idx in primary_indices_list if 0 <= idx < len(train_embeddings_cpu)]\n",
    "                if len(valid_primary_indices) != len(primary_indices_list):\n",
    "                     logging.warning(f\"Some primary indices were out of bounds: {primary_indices_list}. Using only valid ones: {valid_primary_indices}\")\n",
    "\n",
    "                if not valid_primary_indices:\n",
    "                    primary_neighbor_embeddings = np.array([])\n",
    "                else:\n",
    "                    primary_neighbor_embeddings = train_embeddings_cpu[valid_primary_indices]\n",
    "\n",
    "            except IndexError as ie:\n",
    "                logging.error(f\"IndexError retrieving primary embeddings. Indices: {primary_indices_list}, Max index: {len(train_embeddings_cpu)-1}. Error: {ie}\")\n",
    "                primary_neighbor_embeddings = np.array([]) # Fallback\n",
    "\n",
    "            if primary_neighbor_embeddings.shape[0] > 0:\n",
    "                distances_s, indices_s = faiss_index.search(primary_neighbor_embeddings, m_secondary + 1)\n",
    "                for i, primary_idx in enumerate(valid_primary_indices):\n",
    "                    for neighbor_idx in indices_s[i]:\n",
    "                        if neighbor_idx != -1 and neighbor_idx != primary_idx and neighbor_idx not in primary_indices:\n",
    "                            secondary_indices.add(neighbor_idx)\n",
    "\n",
    "        # 5. Combine primary and secondary, limit total\n",
    "        final_indices_list = list(primary_indices)\n",
    "        remaining_needed = max_total - len(final_indices_list)\n",
    "        if remaining_needed > 0:\n",
    "             additional_secondary = [idx for idx in secondary_indices if idx not in final_indices_list]\n",
    "             final_indices_list.extend(additional_secondary[:remaining_needed])\n",
    "        final_indices = final_indices_list[:max_total]\n",
    "\n",
    "        # 6. Retrieve texts\n",
    "        retrieved_texts = []\n",
    "        for i in final_indices:\n",
    "            if 0 <= i < len(train_texts):\n",
    "                retrieved_texts.append(train_texts[i])\n",
    "            else:\n",
    "                logging.warning(f\"Retrieved invalid index {i} during text lookup (max: {len(train_texts)-1}). Skipping.\")\n",
    "\n",
    "        return retrieved_texts\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"ERROR in retrieve_documents_graph_like for query '{query_text[:50]}...': {e}\", exc_info=True)\n",
    "        gc.collect()\n",
    "        if Config.device == torch.device(\"cuda\"): torch.cuda.empty_cache()\n",
    "        return []\n",
    "\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "# Use this guard to ensure the following code only runs when the script is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # --- Multiprocessing Setup ---\n",
    "    try:\n",
    "        current_start_method = mp.get_start_method(allow_none=True)\n",
    "        if current_start_method is None or current_start_method != 'spawn':\n",
    "            if hasattr(mp, 'set_start_method'):\n",
    "                mp.set_start_method('spawn', force=True)\n",
    "                logging.info(f\"Multiprocessing start method set to 'spawn' (was {current_start_method}).\")\n",
    "            else:\n",
    "                logging.warning(\"mp.set_start_method not available. Using default method.\")\n",
    "        else:\n",
    "             logging.info(\"Multiprocessing start method already 'spawn'.\")\n",
    "    except (RuntimeError, ValueError) as e:\n",
    "        logging.warning(f\"Could not force multiprocessing start method to 'spawn': {e}. Using default: {mp.get_start_method(allow_none=True)}\")\n",
    "\n",
    "    # --- Seed and Device Setup ---\n",
    "    np.random.seed(Config.seed)\n",
    "    torch.manual_seed(Config.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(Config.seed)\n",
    "        logging.info(f\"CUDA available. Using device: {Config.device}\")\n",
    "        logging.info(f\"Mixed Precision Training (AMP) enabled: {Config.use_amp}\")\n",
    "    else:\n",
    "        logging.info(f\"CUDA not available. Using device: {Config.device}\")\n",
    "        Config.use_amp = False # Ensure AMP is disabled if no CUDA\n",
    "        logging.info(f\"Mixed Precision Training (AMP) disabled (CUDA not available).\")\n",
    "\n",
    "\n",
    "    # --- Retriever Setup ---\n",
    "    # Assign values to the MODULE-LEVEL global variables\n",
    "    logging.info(\"--- Setting up Retriever ---\")\n",
    "    train_df = None\n",
    "    # *** REMOVED global declaration from here ***\n",
    "    try:\n",
    "        train_df = load_data(Config.train_file)\n",
    "        if train_df is None or train_df.empty:\n",
    "            raise ValueError(\"Failed to load training data for retriever. Cannot proceed.\")\n",
    "\n",
    "        # Assign directly to module-level variables declared at the top\n",
    "        train_texts = train_df['tweet'].tolist()\n",
    "        logging.info(f\"Loading retriever model: {Config.retriever_model_name}...\")\n",
    "\n",
    "        retriever_model = SentenceTransformer(Config.retriever_model_name)\n",
    "        retriever_model.to(Config.device)\n",
    "        logging.info(f\"Retriever model '{Config.retriever_model_name}' loaded and moved to {Config.device}.\")\n",
    "\n",
    "        # --- Embedding ---\n",
    "        logging.info(f\"Embedding {len(train_texts)} training documents for FAISS index...\")\n",
    "        batch_size_embed = 128\n",
    "        train_embeddings = retriever_model.encode(\n",
    "            train_texts,\n",
    "            batch_size=batch_size_embed,\n",
    "            convert_to_tensor=True,\n",
    "            show_progress_bar=True,\n",
    "            device=Config.device\n",
    "        )\n",
    "        logging.info(f\"Embeddings generated with shape: {train_embeddings.shape}\")\n",
    "        train_embeddings_cpu = train_embeddings.cpu().numpy().astype(np.float32) # Assign to module-level global\n",
    "\n",
    "        del train_embeddings; gc.collect()\n",
    "        if Config.device == torch.device(\"cuda\"): torch.cuda.empty_cache()\n",
    "\n",
    "        # --- FAISS Indexing ---\n",
    "        embedding_dim = train_embeddings_cpu.shape[1]\n",
    "        logging.info(f\"Building FAISS index ({Config.faiss_index_type}) with dimension={embedding_dim}...\")\n",
    "\n",
    "        if Config.faiss_index_type == 'FlatL2':\n",
    "            faiss_index = faiss.IndexFlatL2(embedding_dim) # Assign to module-level global\n",
    "            faiss_index.add(train_embeddings_cpu)\n",
    "        elif Config.faiss_index_type == 'IVFFlat':\n",
    "            quantizer = faiss.IndexFlatL2(embedding_dim)\n",
    "            metric = faiss.METRIC_L2\n",
    "            actual_nlist = min(Config.faiss_nlist, len(train_texts))\n",
    "            if actual_nlist != Config.faiss_nlist:\n",
    "                 logging.warning(f\"Adjusted faiss_nlist from {Config.faiss_nlist} to {actual_nlist}\")\n",
    "            if actual_nlist == 0:\n",
    "                 raise ValueError(\"Cannot build IVFFlat index with 0 training vectors or nlist=0.\")\n",
    "\n",
    "            faiss_index = faiss.IndexIVFFlat(quantizer, embedding_dim, actual_nlist, metric) # Assign to module-level global\n",
    "\n",
    "            logging.info(f\"Training FAISS {Config.faiss_index_type} index with nlist={actual_nlist}...\")\n",
    "            if train_embeddings_cpu.shape[0] < actual_nlist:\n",
    "                 logging.warning(f\"Number of training vectors ({train_embeddings_cpu.shape[0]}) is less than nlist ({actual_nlist}).\")\n",
    "            start_train_time = time.time()\n",
    "            faiss_index.train(train_embeddings_cpu)\n",
    "            logging.info(f\"FAISS index training finished in {time.time() - start_train_time:.2f}s.\")\n",
    "\n",
    "            faiss_index.add(train_embeddings_cpu)\n",
    "            faiss_index.nprobe = min(Config.faiss_nprobe, actual_nlist)\n",
    "            logging.info(f\"Set FAISS nprobe to {faiss_index.nprobe}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported faiss_index_type: {Config.faiss_index_type}\")\n",
    "\n",
    "        logging.info(f\"FAISS index built successfully. Type: {Config.faiss_index_type}, Total vectors: {faiss_index.ntotal}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"FATAL: Error during retriever setup: {e}\", exc_info=True); exit(1)\n",
    "\n",
    "\n",
    "    # --- Load Data & Create DataLoaders ---\n",
    "    # This happens *after* the module-level global retriever components are initialized\n",
    "    logging.info(\"--- Loading Data and Creating DataLoaders ---\")\n",
    "    val_df, test_df = None, None\n",
    "    train_dataset, val_dataset, test_dataset = None, None, None\n",
    "    train_dataloader, val_dataloader, test_dataloader = None, None, None\n",
    "    classifier_tokenizer = None\n",
    "\n",
    "    try:\n",
    "        val_df = load_data(Config.val_file)\n",
    "        test_df = load_data(Config.test_file)\n",
    "        if val_df is None or val_df.empty: logging.warning(\"Validation data loading failed or resulted in empty dataframe.\")\n",
    "        if test_df is None or test_df.empty: logging.warning(\"Test data loading failed or resulted in empty dataframe.\")\n",
    "\n",
    "        logging.info(f\"Loading classifier tokenizer: {Config.classifier_model_name}...\")\n",
    "        classifier_tokenizer = AutoTokenizer.from_pretrained(Config.classifier_model_name)\n",
    "        logging.info(\"Classifier tokenizer loaded.\")\n",
    "\n",
    "        # --- Create Datasets ---\n",
    "        logging.info(\"Creating datasets...\")\n",
    "        # Check if module-level train_texts is populated before creating dataset\n",
    "        if not train_texts:\n",
    "             logging.error(\"Cannot create train_dataset as global train_texts is empty (retriever setup likely failed).\")\n",
    "             raise ValueError(\"Training text data is required.\")\n",
    "\n",
    "        # Use train_df for labels if available, otherwise could adapt if labels are separate\n",
    "        if train_df is not None and not train_df.empty:\n",
    "             train_labels = train_df['label'].tolist()\n",
    "             if len(train_texts) != len(train_labels):\n",
    "                  # This case should ideally not happen if train_texts came from train_df\n",
    "                  logging.error(f\"Mismatch between global train_texts ({len(train_texts)}) and train_df labels ({len(train_labels)}).\")\n",
    "                  raise ValueError(\"Text and label count mismatch for training data.\")\n",
    "\n",
    "             train_dataset = GraphRagNewsDataset(\n",
    "                texts=train_texts, # Use module-level global texts\n",
    "                labels=train_labels,\n",
    "                tokenizer=classifier_tokenizer, max_len=Config.max_seq_length,\n",
    "                retriever_func=retrieve_documents_graph_like, # Pass the retrieval function\n",
    "                num_retrieved_total=Config.max_total_retrieved_docs\n",
    "             )\n",
    "        else:\n",
    "             logging.error(\"Cannot create train_dataset as train_df (needed for labels) is invalid or empty.\")\n",
    "             raise ValueError(\"Training data (train_df with labels) is required.\")\n",
    "\n",
    "\n",
    "        if val_df is not None and not val_df.empty:\n",
    "            val_dataset = GraphRagNewsDataset(\n",
    "                texts=val_df['tweet'].tolist(), labels=val_df['label'].tolist(),\n",
    "                tokenizer=classifier_tokenizer, max_len=Config.max_seq_length,\n",
    "                retriever_func=retrieve_documents_graph_like,\n",
    "                num_retrieved_total=Config.max_total_retrieved_docs\n",
    "            )\n",
    "\n",
    "        if test_df is not None and not test_df.empty:\n",
    "            test_dataset = GraphRagNewsDataset(\n",
    "                texts=test_df['tweet'].tolist(), labels=test_df['label'].tolist(),\n",
    "                tokenizer=classifier_tokenizer, max_len=Config.max_seq_length,\n",
    "                retriever_func=retrieve_documents_graph_like,\n",
    "                num_retrieved_total=Config.max_total_retrieved_docs\n",
    "            )\n",
    "        logging.info(\"Datasets created.\")\n",
    "\n",
    "        # --- Determine Number of Workers ---\n",
    "        num_workers = 0\n",
    "        if Config.DEBUG_DATALOADER:\n",
    "            logging.warning(\"DEBUG MODE ACTIVE: Setting num_workers = 0 for DataLoader.\")\n",
    "        else:\n",
    "            if Config.device == torch.device(\"cuda\"):\n",
    "                current_start_method = mp.get_start_method(allow_none=True)\n",
    "                if current_start_method == 'spawn':\n",
    "                    cpu_count = os.cpu_count()\n",
    "                    num_workers = min(4, cpu_count // 2 if cpu_count else 1) if cpu_count else 0\n",
    "                    if num_workers > 0:\n",
    "                        logging.info(f\"Using {num_workers} dataloader workers (CUDA + spawn method detected).\")\n",
    "                    else:\n",
    "                        logging.info(\"Calculated num_workers is 0. Using main process for data loading.\")\n",
    "                else:\n",
    "                    logging.warning(f\"CUDA available but multiprocessing start method is '{current_start_method}' (expected 'spawn'). Using 0 workers for safety.\")\n",
    "            else:\n",
    "                logging.info(\"Not using CUDA. Setting num_workers = 0.\")\n",
    "\n",
    "        pin_memory = (num_workers > 0 and Config.device == torch.device(\"cuda\"))\n",
    "        logging.info(f\"DataLoader pin_memory set to: {pin_memory}\")\n",
    "\n",
    "        # --- Create DataLoaders ---\n",
    "        if train_dataset:\n",
    "            train_dataloader = DataLoader(\n",
    "                train_dataset, batch_size=Config.batch_size, shuffle=True,\n",
    "                num_workers=num_workers, pin_memory=pin_memory, drop_last=True,\n",
    "                # persistent_workers=(num_workers > 0) # Consider persistent workers if stable\n",
    "            )\n",
    "        if val_dataset:\n",
    "            val_num_workers = min(num_workers, 2)\n",
    "            val_pin_memory = (val_num_workers > 0 and Config.device == torch.device(\"cuda\"))\n",
    "            val_dataloader = DataLoader(\n",
    "                val_dataset, batch_size=Config.batch_size, shuffle=False,\n",
    "                num_workers=val_num_workers, pin_memory=val_pin_memory\n",
    "            )\n",
    "        if test_dataset:\n",
    "            test_num_workers = min(num_workers, 2)\n",
    "            test_pin_memory = (test_num_workers > 0 and Config.device == torch.device(\"cuda\"))\n",
    "            test_dataloader = DataLoader(\n",
    "                test_dataset, batch_size=Config.batch_size, shuffle=False,\n",
    "                num_workers=test_num_workers, pin_memory=test_pin_memory\n",
    "            )\n",
    "        logging.info(\"DataLoaders created.\")\n",
    "\n",
    "        if train_dataloader: logging.info(f\"  Train DataLoader: {len(train_dataloader)} batches.\")\n",
    "        else: logging.error(\"Train dataloader creation failed. Training cannot proceed.\"); exit(1)\n",
    "        if val_dataloader: logging.info(f\"  Validation DataLoader: {len(val_dataloader)} batches.\")\n",
    "        else: logging.warning(\"Validation dataloader not created.\")\n",
    "        if test_dataloader: logging.info(f\"  Test DataLoader: {len(test_dataloader)} batches.\")\n",
    "        else: logging.warning(\"Test dataloader not created.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"FATAL: Error during DataLoader creation phase: {e}\", exc_info=True); exit(1)\n",
    "\n",
    "    # --- Model Definition ---\n",
    "    logging.info(\"--- Initializing Classifier Model ---\")\n",
    "    classifier_model_instance = None # Use a different name to avoid confusion with global\n",
    "    try:\n",
    "        logging.info(f\"Loading classifier model: {Config.classifier_model_name}...\")\n",
    "        classifier_model_instance = AutoModelForSequenceClassification.from_pretrained(\n",
    "            Config.classifier_model_name,\n",
    "            num_labels=2 # Binary classification (real/fake)\n",
    "        )\n",
    "        classifier_model_instance.to(Config.device)\n",
    "        logging.info(\"Classifier model loaded and moved to device.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"FATAL: Failed to initialize classifier model: {e}\", exc_info=True); exit(1)\n",
    "\n",
    "    # --- Training Setup ---\n",
    "    logging.info(\"--- Setting up Training Components ---\")\n",
    "    optimizer = None; scheduler = None; loss_fn = None; scaler = None\n",
    "    if train_dataloader and len(train_dataloader) > 0:\n",
    "        try:\n",
    "            # Pass the specific model instance to the optimizer\n",
    "            optimizer = AdamW(classifier_model_instance.parameters(), lr=Config.learning_rate, eps=1e-8)\n",
    "            num_update_steps_per_epoch = len(train_dataloader) // Config.gradient_accumulation_steps\n",
    "            total_steps = num_update_steps_per_epoch * Config.epochs\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=Config.warmup_steps, num_training_steps=total_steps\n",
    "            )\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            scaler = GradScaler(enabled=Config.use_amp)\n",
    "\n",
    "            logging.info(f\"Optimizer, Scheduler, Loss Function, and GradScaler (AMP enabled: {Config.use_amp}) initialized.\")\n",
    "            logging.info(f\"Total training steps (considering grad accum): {total_steps}\")\n",
    "            logging.info(f\"Warmup steps: {Config.warmup_steps}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"FATAL: Error during training setup: {e}\", exc_info=True); exit(1)\n",
    "    else:\n",
    "        logging.error(\"FATAL: Training dataloader is invalid or empty. Cannot setup training components.\"); exit(1)\n",
    "\n",
    "    # --- Training Loop ---\n",
    "    logging.info(\"--- Starting Training ---\")\n",
    "    logging.info(\"Tip: For further speed optimization, consider profiling the code using tools like cProfile or torch.profiler.\")\n",
    "\n",
    "    best_val_f1 = -1.0\n",
    "    global_step = 0\n",
    "    training_start_time = time.time()\n",
    "\n",
    "    for epoch in range(Config.epochs):\n",
    "        logging.info(f\"===== Epoch {epoch + 1}/{Config.epochs} =====\")\n",
    "        epoch_start_time = time.time()\n",
    "        # Use the specific model instance for training\n",
    "        classifier_model_instance.train()\n",
    "        total_train_loss = 0\n",
    "        processed_batches = 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1} Training\", leave=False)\n",
    "        for step, batch in enumerate(progress_bar):\n",
    "            if not isinstance(batch, dict) or 'input_ids' not in batch or 'attention_mask' not in batch or 'labels' not in batch:\n",
    "                logging.warning(f\"Skipping invalid batch (not dict or missing keys) at step {step} in epoch {epoch + 1}.\")\n",
    "                continue\n",
    "            if batch['input_ids'].numel() == 0 or batch['labels'].numel() == 0:\n",
    "                 logging.warning(f\"Skipping empty batch (zero elements) at step {step} in epoch {epoch + 1}.\")\n",
    "                 continue\n",
    "\n",
    "            try:\n",
    "                input_ids = batch['input_ids'].to(Config.device)\n",
    "                attention_mask = batch['attention_mask'].to(Config.device)\n",
    "                labels = batch['labels'].to(Config.device)\n",
    "\n",
    "                with autocast(enabled=Config.use_amp):\n",
    "                    # Use the specific model instance\n",
    "                    outputs = classifier_model_instance(input_ids=input_ids,\n",
    "                                                        attention_mask=attention_mask,\n",
    "                                                        labels=labels)\n",
    "                    loss = outputs.loss\n",
    "\n",
    "                if Config.gradient_accumulation_steps > 1:\n",
    "                    loss = loss / Config.gradient_accumulation_steps\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                total_train_loss += loss.item() * Config.gradient_accumulation_steps\n",
    "                processed_batches += 1\n",
    "\n",
    "                if (step + 1) % Config.gradient_accumulation_steps == 0 or (step + 1) == len(train_dataloader):\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    # Clip gradients for the specific model instance\n",
    "                    torch.nn.utils.clip_grad_norm_(classifier_model_instance.parameters(), 1.0)\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "                    if scheduler: scheduler.step()\n",
    "                    global_step += 1\n",
    "\n",
    "                    current_lr = scheduler.get_last_lr()[0] if scheduler else Config.learning_rate\n",
    "                    progress_bar.set_postfix({\n",
    "                        'loss': f\"{loss.item() * Config.gradient_accumulation_steps:.4f}\",\n",
    "                        'lr': f\"{current_lr:.2e}\",\n",
    "                        'scale': f\"{scaler.get_scale():.1f}\",\n",
    "                        'step': global_step\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error during training step {step} in epoch {epoch + 1}: {e}\", exc_info=True)\n",
    "                logging.warning(\"Attempting to skip problematic batch and continue training...\")\n",
    "                optimizer.zero_grad()\n",
    "                del batch, input_ids, attention_mask, labels\n",
    "                if 'outputs' in locals(): del outputs\n",
    "                if 'loss' in locals(): del loss\n",
    "                gc.collect()\n",
    "                if Config.device == torch.device(\"cuda\"): torch.cuda.empty_cache()\n",
    "                continue\n",
    "\n",
    "        progress_bar.close()\n",
    "        epoch_duration = time.time() - epoch_start_time\n",
    "        avg_train_loss = total_train_loss / processed_batches if processed_batches > 0 else 0\n",
    "        current_lr = scheduler.get_last_lr()[0] if scheduler else Config.learning_rate\n",
    "        logging.info(f\"Epoch {epoch + 1} completed in {epoch_duration:.2f}s.\")\n",
    "        logging.info(f\"  Average Training Loss: {avg_train_loss:.4f}\")\n",
    "        logging.info(f\"  Current Learning Rate: {current_lr:.2e}\")\n",
    "        logging.info(f\"  AMP Scale Factor: {scaler.get_scale():.1f}\")\n",
    "\n",
    "        # --- Validation Step ---\n",
    "        if val_dataloader and len(val_dataloader) > 0:\n",
    "            logging.info(\"--- Evaluating on Validation Set ---\")\n",
    "            # Pass the specific model instance for evaluation\n",
    "            val_loss, val_acc, val_prec, val_rec, val_f1 = evaluate_model(\n",
    "                classifier_model_instance, val_dataloader, Config.device, loss_fn\n",
    "            )\n",
    "\n",
    "            if val_f1 > best_val_f1:\n",
    "                logging.info(f\"Validation F1 improved ({best_val_f1:.4f} --> {val_f1:.4f}). Saving model...\")\n",
    "                best_val_f1 = val_f1\n",
    "                os.makedirs(Config.output_dir, exist_ok=True)\n",
    "                # Save the specific model instance\n",
    "                classifier_model_instance.save_pretrained(Config.output_dir)\n",
    "                if classifier_tokenizer: classifier_tokenizer.save_pretrained(Config.output_dir)\n",
    "                logging.info(f\"Model saved to {Config.output_dir}\")\n",
    "            else:\n",
    "                logging.info(f\"Validation F1 did not improve ({val_f1:.4f}). Best F1: {best_val_f1:.4f}\")\n",
    "        else:\n",
    "            logging.warning(\"Skipping validation: Validation dataloader not available or empty.\")\n",
    "\n",
    "        gc.collect()\n",
    "        if Config.device == torch.device(\"cuda\"): torch.cuda.empty_cache()\n",
    "\n",
    "    # --- End of Training Loop ---\n",
    "    training_duration = time.time() - training_start_time\n",
    "    logging.info(f\"--- Training Finished --- (Total Duration: {training_duration:.2f} seconds)\")\n",
    "    logging.info(f\"Best Validation F1 achieved: {best_val_f1:.4f}\")\n",
    "\n",
    "    # --- Final Evaluation on Test Set ---\n",
    "    if test_dataloader and len(test_dataloader) > 0:\n",
    "        logging.info(\"--- Evaluating on Test Set using the Best Model ---\")\n",
    "        try:\n",
    "            best_model_path = Config.output_dir\n",
    "            model_file_path_bin = os.path.join(best_model_path, \"pytorch_model.bin\")\n",
    "            model_file_path_safe = os.path.join(best_model_path, \"model.safetensors\")\n",
    "            config_file_path = os.path.join(best_model_path, \"config.json\")\n",
    "            tokenizer_config_path = os.path.join(best_model_path, \"tokenizer_config.json\")\n",
    "\n",
    "            essential_files_exist = (\n",
    "                os.path.exists(model_file_path_bin) or os.path.exists(model_file_path_safe)\n",
    "            ) and os.path.exists(config_file_path) and os.path.exists(tokenizer_config_path)\n",
    "\n",
    "            if essential_files_exist:\n",
    "                logging.info(f\"Loading best model from {best_model_path} for final test evaluation...\")\n",
    "                best_model_instance = AutoModelForSequenceClassification.from_pretrained(best_model_path)\n",
    "                best_tokenizer = AutoTokenizer.from_pretrained(best_model_path)\n",
    "                best_model_instance.to(Config.device)\n",
    "                logging.info(\"Best model and tokenizer loaded successfully.\")\n",
    "\n",
    "                logging.info(\"Re-creating test dataset and dataloader with loaded best tokenizer...\")\n",
    "                if test_df is not None and not test_df.empty:\n",
    "                    test_dataset_final = GraphRagNewsDataset(\n",
    "                        texts=test_df['tweet'].tolist(), labels=test_df['label'].tolist(),\n",
    "                        tokenizer=best_tokenizer,\n",
    "                        max_len=Config.max_seq_length,\n",
    "                        retriever_func=retrieve_documents_graph_like,\n",
    "                        num_retrieved_total=Config.max_total_retrieved_docs\n",
    "                    )\n",
    "                    num_workers_test = 0\n",
    "                    pin_memory_test = False\n",
    "                    test_dataloader_final = DataLoader(\n",
    "                        test_dataset_final, batch_size=Config.batch_size, shuffle=False,\n",
    "                        num_workers=num_workers_test, pin_memory=pin_memory_test\n",
    "                    )\n",
    "                    logging.info(f\"Final test dataloader created with {len(test_dataloader_final)} batches.\")\n",
    "\n",
    "                    logging.info(\"Evaluating best model on the final test set...\")\n",
    "                    final_loss_fn = loss_fn if 'loss_fn' in locals() and loss_fn is not None else None\n",
    "                    if final_loss_fn is None: logging.warning(\"Loss function not available for final test evaluation.\")\n",
    "                    # Evaluate the loaded best model instance\n",
    "                    evaluate_model(best_model_instance, test_dataloader_final, Config.device, final_loss_fn)\n",
    "                else:\n",
    "                    logging.error(\"Cannot perform final evaluation: Test data (test_df) is unavailable or empty.\")\n",
    "\n",
    "            # Fallback: Use the model instance from the end of training if no best model was saved\n",
    "            elif classifier_model_instance:\n",
    "                logging.warning(\"No saved best model found or essential files missing.\")\n",
    "                logging.warning(\"Evaluating using the model's final state after training...\")\n",
    "                final_loss_fn = loss_fn if 'loss_fn' in locals() and loss_fn is not None else None\n",
    "                if final_loss_fn is None: logging.warning(\"Loss function not available for final test evaluation.\")\n",
    "                # Evaluate the final state model instance\n",
    "                evaluate_model(classifier_model_instance, test_dataloader, Config.device, final_loss_fn)\n",
    "            else:\n",
    "                logging.error(\"Skipping final evaluation: No model available.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during final test evaluation phase: {e}\", exc_info=True)\n",
    "    else:\n",
    "        logging.warning(\"Skipping final evaluation: Test dataloader not available or empty.\")\n",
    "\n",
    "    logging.info(\"--- Script Finished ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da7b2463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1684d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
